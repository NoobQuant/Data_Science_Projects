{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to investigate segmented regression results vs. results from separate regressions. Some links to relevant StackOverflow threads:\n",
    "\n",
    " - [Link 1](https://stats.stackexchange.com/a/13115/162538)\n",
    " - [Link 2](https://stats.stackexchange.com/a/12809/162538)\n",
    " - [Link 3](https://stats.stackexchange.com/a/468666/162538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "#warnings.filterwarnings('ignore')\n",
    "np.random.seed(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true data generating process:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "  y_t=\\begin{cases}\n",
    "    b_1 x_t + a_1 m_t + u_t, & t \\leq t^{*}\\\\\n",
    "    b_2 x_t + a_2 m_t + u_t, & t > t^{*}\n",
    "  \\end{cases}\n",
    "\\end{equation*},\n",
    "$$\n",
    "\n",
    "where $t = 1, \\dots , T$ and $u_{t} \\sim N(\\mu_{u}, \\sigma_{u})$ denotes (Normally distributed) random noise term. Distribution for exogenous variable $x_{t} = m_t + i_t$ with $i_{t} \\sim N(-4, 10)$ and $m_t \\sim $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "T = 300\n",
    "tstar = 110\n",
    "periods = list(np.arange(1, T+1))\n",
    "mu_u = 0\n",
    "sigma_u = 1\n",
    "b_1 = 1\n",
    "b_2 = 3\n",
    "a_1 = -1.5\n",
    "a_2 = -0.9\n",
    "\n",
    "# Generate random data\n",
    "df = pd.DataFrame(np.random.normal(mu_u, sigma_u, [T, 1]), columns=[\"u\"], index=periods)\n",
    "df.index.names = [\"time\"]\n",
    "df[\"m\"] = np.random.exponential(2.1, [T, 1])\n",
    "df[\"x\"] = df[\"m\"] + np.random.normal(-4, 10, T)\n",
    "df[\"y\"] = np.where(\n",
    "    df.index<=tstar,\n",
    "    b_1 * df[\"x\"] + a_1 * df[\"m\"] + df[\"u\"],\n",
    "    b_2 * df[\"x\"] + a_2 * df[\"m\"] + df[\"u\"]\n",
    ")\n",
    "\n",
    "# Add post dummy and interact with x\n",
    "df[\"post\"] = np.where(df.index<=tstar, 0, 1)\n",
    "df[\"x_post\"] = df[\"post\"] * df[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressions:\n",
    "\n",
    " 1. Segmented regression $y = \\gamma_1 x_t + \\gamma_2 x_t Post_t + \\epsilon_{1,t}$\n",
    " 2. Pre-sample regression $y = \\beta_1 x_t + \\epsilon_{2,t}$\n",
    " 3. Post-sample regression $y = \\beta_2 x_t + \\epsilon_{3,t}$\n",
    " \n",
    "where $Post_t = 0$ when $t\\leq t^{*}$, otherwise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = {\n",
    "    \"segmented\": {\n",
    "        \"formula\": \"y ~ -1 + x + x_post\",\n",
    "        \"data\": df.copy(),\n",
    "    },\n",
    "    \"pre\": {\n",
    "        \"formula\": \"y ~ -1 + x\",\n",
    "        \"data\": df[df.index <= tstar].copy(),\n",
    "    },\n",
    "    \"post\": {\n",
    "        \"formula\": \"y ~ -1 + x\",\n",
    "        \"data\": df[df.index > tstar].copy(),\n",
    "    },\n",
    "}\n",
    "\n",
    "items = deepcopy(list(regs.keys()))\n",
    "for key in items:    \n",
    "    regs[key][\"res\"] = sm.OLS.from_formula(regs[key][\"formula\"], data=regs[key][\"data\"]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.971\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.971\n",
      "Method:                 Least Squares   F-statistic:                              5074.\n",
      "Date:                Sun, 02 Jan 2022   Prob (F-statistic):                   6.79e-231\n",
      "Time:                        20:32:28   Log-Likelihood:                         -830.41\n",
      "No. Observations:                 300   AIC:                                      1665.\n",
      "Df Residuals:                     298   BIC:                                      1672.\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x              0.8869      0.039     22.983      0.000       0.811       0.963\n",
      "x_post         2.1051      0.049     42.795      0.000       2.008       2.202\n",
      "==============================================================================\n",
      "Omnibus:                      199.728   Durbin-Watson:                   1.133\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2342.018\n",
      "Skew:                          -2.576   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.682   Cond. No.                         2.99\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "----------------------------------------\n",
      "Separate t-test for x + x_post = 0: \n",
      "                             Test for Constraints                             \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "c0             2.9920      0.031     98.083      0.000       2.932       3.052\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(regs[\"segmented\"][\"res\"].summary())\n",
    "print(\"\")\n",
    "print(\"-\"*40)\n",
    "print(\"Separate t-test for x + x_post = 0: \")\n",
    "print(regs[\"segmented\"][\"res\"].t_test(\"x + x_post = 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.728\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.726\n",
      "Method:                 Least Squares   F-statistic:                              291.9\n",
      "Date:                Sun, 02 Jan 2022   Prob (F-statistic):                    1.33e-32\n",
      "Time:                        20:32:28   Log-Likelihood:                         -336.98\n",
      "No. Observations:                 110   AIC:                                      676.0\n",
      "Df Residuals:                     109   BIC:                                      678.7\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x              0.8869      0.052     17.085      0.000       0.784       0.990\n",
      "==============================================================================\n",
      "Omnibus:                       79.002   Durbin-Watson:                   1.159\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              486.000\n",
      "Skew:                          -2.423   Prob(JB):                    2.93e-106\n",
      "Kurtosis:                      12.086   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(regs[\"pre\"][\"res\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.990\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.990\n",
      "Method:                 Least Squares   F-statistic:                          1.805e+04\n",
      "Date:                Sun, 02 Jan 2022   Prob (F-statistic):                   1.69e-189\n",
      "Time:                        20:32:28   Log-Likelihood:                         -466.28\n",
      "No. Observations:                 190   AIC:                                      934.6\n",
      "Df Residuals:                     189   BIC:                                      937.8\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x              2.9920      0.022    134.348      0.000       2.948       3.036\n",
      "==============================================================================\n",
      "Omnibus:                       36.816   Durbin-Watson:                   1.073\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.302\n",
      "Skew:                          -1.093   Prob(JB):                     1.62e-12\n",
      "Kurtosis:                       4.443   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(regs[\"post\"][\"res\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s=3.86690, s_check=3.86690, s1=5.20203, s2=2.82308\n",
      "se_x_post=0.04919, se_x_post_check=0.04919\n"
     ]
    }
   ],
   "source": [
    "# Regression model standard errors\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.scale.html#statsmodels.regression.linear_model.RegressionResults.scale\n",
    "s = np.sqrt(regs[\"segmented\"][\"res\"].scale)\n",
    "s1 = np.sqrt(regs[\"pre\"][\"res\"].scale)\n",
    "s2 = np.sqrt(regs[\"post\"][\"res\"].scale)\n",
    "s_check = np.sqrt(\n",
    "    (\n",
    "        (regs[\"pre\"][\"res\"].nobs - len(regs[\"pre\"][\"res\"].params)) * np.power(s1, 2) + \\\n",
    "        (regs[\"post\"][\"res\"].nobs - len(regs[\"post\"][\"res\"].params)) * np.power(s2, 2)\n",
    "    ) / \\\n",
    "    (regs[\"pre\"][\"res\"].nobs + regs[\"post\"][\"res\"].nobs - 2*len(regs[\"pre\"][\"res\"].params))\n",
    ")\n",
    "print(\"s={:.5f}, s_check={:.5f}, s1={:.5f}, s2={:.5f}\".format(s, s_check, s1, s2))\n",
    "\n",
    "# Standard errors for estimate x_post\n",
    "se_x_post = regs[\"segmented\"][\"res\"].bse[\"x_post\"]\n",
    "se_x_post_check = s * np.sqrt(\n",
    "    np.power(regs[\"pre\"][\"res\"].bse[\"x\"] / s1, 2) + np.power(regs[\"post\"][\"res\"].bse[\"x\"] / s2, 2)\n",
    ")\n",
    "print(\"se_x_post={:.5f}, se_x_post_check={:.5f}\".format(se_x_post, se_x_post_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show what is going on under the OLS estimation hood as formulas. The segmented regressions equation is\n",
    "\n",
    "$y = \\gamma_1 x_t + \\gamma_2 x_t Post_t + \\epsilon_{1,t}$\n",
    "\n",
    "Define $z_t \\equiv [x_t \\ , \\ x_t Post_t]$ and $A \\equiv \\begin{bmatrix} \\gamma_1 \\\\ \\gamma_2 \\end{bmatrix} $ and rewrite\n",
    "\n",
    "$y = z_t A + \\epsilon_{1,t}$\n",
    "\n",
    "Now stack matrices in time dimension; define a $Tx1$ matrix $Y \\equiv \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_T \\end{bmatrix} $, a $Tx2$ matrix $Z \\equiv \\begin{bmatrix} z_1 \\\\ \\vdots \\\\ z_T \\end{bmatrix} $ and a $Tx1$ matrix $E_1 \\equiv \\begin{bmatrix} \\epsilon{1,t} \\\\ \\vdots \\\\ \\epsilon{1,T} \\end{bmatrix} $. The regression equation can be written as\n",
    "\n",
    "$Y = Z A + E_1$\n",
    "\n",
    "The least-squares estimate from above regression is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{A} = \\begin{bmatrix} \\hat{\\gamma}_1 \\\\ \\hat{\\gamma}_2 \\end{bmatrix} &= (Z'Z)^{-1} (Z'Y) \\\\[6pt]\n",
    "    &= \\Big(\\begin{bmatrix} x_1 & \\cdots & x_T \\\\ x_1 Post_1 & \\cdots & x_T Post_T \\end{bmatrix}\n",
    "           \\begin{bmatrix} x_1 & x_1 Post_1 \\\\ \\vdots & \\vdots \\\\ x_T & x_T Post_T \\end{bmatrix}\\Big)^{-1}\n",
    "    \\Big(\\begin{bmatrix} x_1 & \\cdots & x_T \\\\ x_1 Post_1 & \\cdots & x_T Post_T \\end{bmatrix}\n",
    "           \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_T \\end{bmatrix}\\Big) \\\\[6pt]\n",
    "    &= \\begin{bmatrix} x_1^2 + \\dots + x_T^2 & x_1^2 Post_1 + \\dots + x_T^2 Post_T \\\\ x_1^2 Post_1 + \\dots + x_T^2 Post_T & x_1^2 Post_1^2 + \\dots + x_T^2 Post_T^2 \\end{bmatrix}^{-1}\n",
    "    \\begin{bmatrix} x_1 y_1 + \\cdots + x_T y_T \\\\ x_1 Post_1 y_1 + \\cdots + x_T Post_T y_T \\end{bmatrix} \\\\[6pt]\n",
    "    &= \\begin{bmatrix} x_1^2 + \\dots + x_T^2 \\ (=a) & x_1^2 Post_1 + \\dots + x_{t^*}^2 Post_{t^*} + \\dots + x_T^2 Post_T \\ (=b) \\\\ x_1^2 Post_1 + \\dots + x_{t^*}^2 Post_{t^*} + \\dots + x_T^2 Post_T \\ (=c) & x_1^2 Post_1^2 + \\dots + x_{t^*}^2 Post_{t^*}^2 + \\dots + x_T^2 Post_T^2 \\ (=d) \\end{bmatrix}^{-1}\n",
    "    \\begin{bmatrix} x_1 y_1 + \\cdots + x_T y_T \\\\ x_1 Post_1 y_1 + \\dots + x_{t^*} Post_{t^*} y_{t^*} + \\cdots + x_T Post_T y_T \\end{bmatrix} \\\\[6pt]\n",
    "    &= \\frac{1}{ad-bc} \\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}\n",
    "    \\begin{bmatrix} x_1 y_1 + \\cdots + x_T y_T \\\\ x_1 Post_1 y_1 + \\dots + x_{t^*} Post_{t^*} y_{t^*} + \\cdots + x_T Post_T y_T \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From above it seems that the point estimate $\\hat{\\gamma}_1$ would not be equivalent to pre-sample $\\beta_1$ because if all the extra terms that appeat, but it is hard to say. At least above in the examples they do turn out to be equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2021_py",
   "language": "python",
   "name": "dev2021_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
