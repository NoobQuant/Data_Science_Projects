{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding SVAR contemporaneous causality via the Frisch-Slutzky paradigm\n",
    "\n",
    "**Under construction!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural vector autoregressive models, as typically used in economics, can be understood as dynamic structural equation models (DSEMs) in which restrictions have been imposed on the impact multiplier matrix and the lagged values are left unrestricted (Killian & Lütkepohl 2017, p.177). This means that causal analysis in SVAR models requires making identifying assumptions only based on contemporaneous causal relations. Justification for this can be traced back to the Frisch-Slutzky paradigm of business cycles, where fluctuations in macroeconomic variables are understood to be driven by sequences of \"structural shocks\", which represent news, changes in preferences, exogenous events, etc. that throw the economy off its stable long-run path.\n",
    "\n",
    "The Frisch-Slutzky paradigm states (Stock & Watson 2018, p. 7) that $n \\times 1$ vector of observed (stationary) macroeconomic variables $Y_t$ can be written in terms of current and past values of $m \\times 1$ vector of structural shocks (including measurement errors) $\\epsilon_T$. That is,\n",
    "\n",
    "\\begin{align*}\n",
    "Y_t = \\sum_{h=0}^{H} \\Theta_h (L^h) \\epsilon_t \\ ,\n",
    "\\end{align*}\n",
    "\n",
    "where $H$ may be $\\infty$ and individual shocks in $\\epsilon_t$ are mutually uncorrelated. Later in 1938, Herman Wold established a link between the moving average formulation and Udny Yule's autoregressive formulation, providing the basis for the main tradition in time-series modeling (Barnett, 2006). This work also saw the birth of *Wold's theorem*, proving that a stationary series can indeed be expressed as a sum of a deterministic component and a stochastic component, which can itself be expressed as an infinite moving average. Wold's proof guarantees the existence of such representation, but the interpretation of the nature of shocks driving the variables is another question: can some real, causal interpretation be given to $\\epsilon_t$ or are they just some artificial moving-average terms? Barnett (2006) argues that while this is still a debated issue, Slutzky himself favored the 'real' interpretation.\n",
    "\n",
    "If one is willing to accept the real, or structural, interpretation of $\\epsilon_t$, the consequences are rather remarkable: observed macroeconomic variables $Y_t$ are merely accounting residuals, borne by structural, possibly very abstract \"shocks\" driving the economy (e.g., \"demand shock affected GDP\"). Sometimes the shocks could also have an observed interpretation (\"shock to policy rate affected house prices\"). If we could measure all the structural shock series, causal inference on measured macroeconomic variables would be simple: we could just include the shocks as observables in our models and estimate what effect they have on observed variables. The obvious problem is that typically the driving forces (shocks) are too abstract to be measured (supply, demand, expectations, preferences, etc.), yielding a violation of *causal sufficiency*; we cannot measure all common causes affecting the system we are interested in. Due to this, the econometric literature has come up with various ways to identify the exogenous shock series driving the economy.\n",
    "\n",
    "SVAR models, as envisaged by Sims (1980) and refinded afterwards by many authors, tap into the Frisch-Slutzky paradigm by combining contemporaneous (time $t$) identification of underlying shocks with a purely statistical/associational vector autoregression model (VAR) to model the lag structure between variables (which is of lesser interest from a causal inference point of view). In other words, SVAR models assume a) no causal mechanisms between the system's observed variable lag structure and b) no contemporaneous causal mechanisms between the system's observed variables but rather between driving shocks and observed variables (unless innovations in observed variables as such are among the driving forces $\\epsilon_t$, in which case contemporaneous causality can be interpreted to exist between observables; this happens only in special cases (Killian & Lütkepohl 2017, p. 112)).\n",
    "\n",
    "Rambachan & Shephard (2019, p. 35) note that the assumptions behind the causal equivalence of the Frisch-Slutzky paradigm and SVAR model are the invertible impact multiplier matrix (a typical explicit SVAR assumption) and I-additive causal effects (typically assumed implicitly in SVAR literature).\n",
    "\n",
    "Causal investigations in SVARs are restricted to responses in observable variables to time $t$ structural shocks, or so-called *impulse responses*. As put by Stock & Watson (2018), structural shocks are to macroeconomists what random treatment is to microeconomists. When a shock hits the economy, it may have an immediate impact on variables in the system, and this effect is propagated through the lag structure to future values of observables. Sometimes this propagation of treatment (shock) is referred to as *treatment path* (Ghannem & Smith 2018, p. 8), but I would refrain from such use because there is a danger of confusing this with assigning treatment (shock) in multiple consecutive time periods, something that SVARs as usually presented cannot directly take into account. Impulse responses answer the following question: what is the average effect of a given shock at time $t$ on future values of observables? Notice that we are looking at the effects of a one-off treatment.\n",
    "\n",
    "An example of a special case where shocks are interpretable in terms of observables is identification via Cholesky decomposition.\n",
    "\n",
    "**Write rest! Idea:**\n",
    "\n",
    " - What about giving a causal interpretation to the lag structure as well? Wouldn't this be along the lines of DSEM? It seems to be [Pearl's view](http://causality.cs.ucla.edu/blog/index.php/2020/01/29/on-imbens-comparison-of-two-approaches-to-empirical-economics/) that meaningful SCMs can be written in terms of observables. Sims criticized DSEMs for good reason, but nowadays we have, e.g., data-driven methods for identifying them; see the literature on causal discovery in a time series context.\n",
    " - Killian and Lütkepohl (2017, p. 239) critize the SCM approach (\"graph theoretic approach\", which I think is a poor term) explicitly for not following the Frisch-Slutzky paradigm: *\"In fact, it is not clear how to interpret statements about one variable causing another from an economic point of view, because structural shocks in simulataneous equations models in general are not associated with specific observables\"*.\n",
    " - If we don't want to abandon the Frisch-Slutzky paradigm completely; would there be equivalent SCMs in terms of observables only with those coming out of the Frisch-Slutzky paradigm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    " - Barnett (2006): Chancing an interpretation: Slutsky’s random cycles revisited.\n",
    " - Ghannem & Smith (2018): Causality in Structural Vector Autoregressions: Science or Sorcery?\n",
    " - Killian & Lütkepohl (2017): Structural vector autoregressive analysis.\n",
    " - Stock & Watson (2018): Identification and estimation of dynamic causal effects in macroeconomics using external instruments.\n",
    " - Sims (1980): Macroeconomics and reality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2023a_py",
   "language": "python",
   "name": "dev2023a_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
